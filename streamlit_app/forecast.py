ä»¥ä¸‹æ˜¯ `streamlit_app/forecast.py` æ–‡ä»¶çš„å®Œæ•´ä»£ç ï¼š

```python
# ä¿®æ”¹åçš„ä»£ç 
import streamlit as st
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from datetime import datetime
import os

# æ¨¡å‹è·¯å¾„
MODEL_PATH = "models/best_lstm_model.pth"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# LSTM æ¨¡å‹ç»“æ„
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers=1, output_size=1):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.linear = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.linear(out[:, -1, :])
        return out

# è½½å…¥æ¨¡å‹
@st.cache_resource
def load_model(input_size, hidden_size, num_layers):
    model = LSTMModel(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)
    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
    model.to(DEVICE)
    model.eval()
    return model

# æ•°æ®æ ‡å‡†åŒ–
def normalize_input(data):
    return (data - data.mean()) / (data.std() + 1e-8)

# é¢„æµ‹å‡½æ•°
def make_forecast(model, input_tensor):
    input_tensor = input_tensor.to(DEVICE)
    with torch.no_grad():
        prediction = model(input_tensor)
    return prediction.cpu().numpy()

# Streamlit ä¸»ç•Œé¢
def run_forecast_module():
    st.title("ğŸŒ§ï¸ æ´ªæ°´é¢„æŠ¥æ¨¡å—")
    st.write("ä¸Šä¼ æœ€æ–°æ°”è±¡æ•°æ®ï¼ˆExcel æˆ– CSVï¼‰ï¼Œè¿›è¡Œæœªæ¥æœˆå¾„æµé¢„æµ‹ã€‚")

    # ç”¨æˆ·è¾“å…¥æ¨¡å‹å‚æ•°
    st.sidebar.header("æ¨¡å‹å‚æ•°é…ç½®")
    input_size = st.sidebar.number_input("è¾“å…¥ç‰¹å¾æ•° (input_size)", min_value=1, value=4)
    hidden_size = st.sidebar.number_input("éšè—å±‚å¤§å° (hidden_size)", min_value=1, value=64)
    num_layers = st.sidebar.number_input("LSTM å±‚æ•° (num_layers)", min_value=1, value=1)
    input_seq_len = st.sidebar.number_input("è¾“å…¥æ—¶é—´æ­¥é•¿ (input_seq_len)", min_value=1, value=12)  # é»˜è®¤ 12 ä¸ªæœˆ
    output_seq_len = st.sidebar.number_input("è¾“å‡ºæ—¶é—´æ­¥é•¿ (output_seq_len)", min_value=1, value=1)  # é»˜è®¤ 1 ä¸ªæœˆ

    # æä¾›æ•°æ®æ¨¡æ¿ä¸‹è½½
    if st.sidebar.button("ğŸ“¥ ä¸‹è½½æ•°æ®æ¨¡æ¿"):
        st.sidebar.write("æ•°æ®æ¨¡æ¿ï¼š")
        st.sidebar.write("date,evaporation_from_bare_soil_sum,total_precipitation_sum,temperature_2m_max,wind_speed_10m")
        st.sidebar.write("2025-01-01,1.2,3.4,5.6,7.8")
        st.sidebar.write("...")

    # æ”¯æŒæ‰‹åŠ¨è¾“å…¥æ•°æ®
    manual_input = st.checkbox("æ‰‹åŠ¨è¾“å…¥æ•°æ®")
    if manual_input:
        st.write("è¯·æ‰‹åŠ¨è¾“å…¥æ•°æ®ï¼ˆä»¥é€—å·æˆ–åˆ¶è¡¨ç¬¦åˆ†éš”ï¼‰ï¼š")
        raw_data = st.text_area("è¾“å…¥æ ¼å¼ï¼šdate,evaporation_from_bare_soil_sum,total_precipitation_sum,temperature_2m_max,wind_speed_10m\nä¾‹å¦‚ï¼š2025-01-01,1.2,3.4,5.6,7.8")
        try:
            from io import StringIO
            if ',' in raw_data:
                df = pd.read_csv(StringIO(raw_data))
            else:
                df = pd.read_csv(StringIO(raw_data), sep="\t")
            st.write("âœ… æ•°æ®é¢„è§ˆï¼š", df.head())
        except Exception as e:
            st.error(f"âŒ æ•°æ®æ ¼å¼æœ‰è¯¯ï¼š{e}")
            return
    else:
        uploaded_file = st.file_uploader("ğŸ“¤ ä¸Šä¼  Excel æˆ– CSV æ–‡ä»¶ï¼ˆéœ€åŒ…å«: date, evaporation_from_bare_soil_sum, total_precipitation_sum, temperature_2m_max, wind_speed_10m åˆ—ï¼‰", type=["csv", "xlsx"])
        if uploaded_file:
            try:
                if uploaded_file.name.endswith(".csv"):
                    df = pd.read_csv(uploaded_file)
                elif uploaded_file.name.endswith(".xlsx"):
                    df = pd.read_excel(uploaded_file)
                st.write("âœ… æ•°æ®é¢„è§ˆï¼š", df.head())
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{e}")
                return
        else:
            st.warning("è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶æˆ–åˆ‡æ¢åˆ°æ‰‹åŠ¨è¾“å…¥æ¨¡å¼ã€‚")
            return

    # æ•°æ®æ£€æŸ¥å’Œå¤„ç†
    try:
        # ä¿®æ”¹åçš„å¿…éœ€åˆ—
        required_columns = ['date', 'evaporation_from_bare_soil_sum', 'total_precipitation_sum', 'temperature_2m_max', 'wind_speed_10m']
        if not set(required_columns).issubset(df.columns):
            missing_cols = set(required_columns) - set(df.columns)
            st.error(f"âŒ ç¼ºå°‘æ‰€éœ€åˆ—ï¼š{missing_cols}")
            return

        features = normalize_input(features)
        features_tensor = torch.tensor(features[-input_seq_len:]).unsqueeze(0)  # (1, seq_len, input_size)

        # åŠ¨æ€åŠ è½½æ¨¡å‹
        model = load_model(input_size, hidden_size, num_layers)

        # æ‰§è¡Œé¢„æµ‹
        prediction = make_forecast(model, features_tensor)
        st.success(f"ğŸŒŠ é¢„æµ‹ç»“æœï¼šæœªæ¥ {output_seq_len} å¾„æµé‡ä¸º **{prediction[0][0]:.2f} mÂ³/s**")

    except Exception as e:
        st.error(f"âŒ å¤„ç†æ•°æ®æ—¶å‡ºé”™ï¼š{e}")

# è¿è¡Œä¸»æ¨¡å—
if __name__ == "__main__":
    run_forecast_module()
```
