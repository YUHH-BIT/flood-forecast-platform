import streamlit as st
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import json
from datetime import datetime, timedelta
from io import StringIO, BytesIO
import openpyxl
from openpyxl.utils import get_column_letter
from openpyxl.worksheet.datavalidation import DataValidation

# å‚æ•°é…ç½®
DATA_COLUMNS = ['evaporation_from_bare_soil_sum',
                'total_precipitation_sum',
                'temperature_2m_max',
                'wind_speed_10m']

INPUT_SIZE = len(DATA_COLUMNS)

# åŠ è½½æ¨¡å‹å‚æ•°
with open("models/best_params.json", "r") as f:
    best_params = json.load(f)

# æ¨¡å‹å®šä¹‰
class LSTMRunoffModel(nn.Module):
    def __init__(self, input_size, hidden_size1, hidden_size2, dropout=0.1):
        super().__init__()
        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=hidden_size1, batch_first=True)
        self.lstm2 = nn.LSTM(input_size=hidden_size1, hidden_size=hidden_size2, batch_first=True)
        self.fc = nn.Linear(hidden_size2, 1)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        out, _ = self.lstm1(x)
        out = self.dropout(out)
        out, _ = self.lstm2(out)
        out = self.fc(out)
        return out.squeeze(-1)

@st.cache_resource
def load_model():
    model = LSTMRunoffModel(INPUT_SIZE, best_params['hidden_size1'], best_params['hidden_size2'], best_params['dropout'])
    model.load_state_dict(torch.load("models/best_lstm_model.pth", map_location="cpu"))
    model.eval()
    return model

def create_excel_template(history_days):
    wb = openpyxl.Workbook()
    ws_data = wb.active
    ws_data.title = "æ•°æ®è¾“å…¥"
    ws_guide = wb.create_sheet(title="å¡«å†™æŒ‡å—")

    headers = ['date'] + DATA_COLUMNS
    ws_data.append(headers)

    for col_idx, header in enumerate(headers, 1):
        col_letter = get_column_letter(col_idx)
        ws_data.column_dimensions[col_letter].width = 22 if header != 'date' else 15

    today = datetime.now()
    for i in range(1, history_days + 1):
        date_cell = ws_data[f'A{i+1}']
        date_cell.value = f"{(today + timedelta(days=i-1)).strftime('%Y-%m-%d')}"
        date_cell.number_format = 'yyyy-mm-dd'
        for col_idx in range(2, 6):
            cell = ws_data[f'{get_column_letter(col_idx)}{i+1}']
            dv = DataValidation(type="decimal", operator="greaterThan", formula1="-1000")
            dv.error = 'è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å€¼ï¼'
            dv.errorTitle = 'è¾“å…¥é”™è¯¯'
            ws_data.add_data_validation(dv)
            dv.add(cell)

    ws_data[f'A{history_days + 3}'] = f"âš ï¸ æ³¨æ„ï¼šè¯·å¡«å†™å®Œæ•´{history_days}å¤©çš„è¿ç»­æ•°æ®ï¼Œä¸å¯ç•™ç©º"
    ws_data[f'A{history_days + 3}'].font = openpyxl.styles.Font(color="FF0000", bold=True)

    ws_guide['A1'] = "æ•°æ®å¡«å†™æŒ‡å—"
    ws_guide['A1'].font = openpyxl.styles.Font(size=16, bold=True)

    field_descriptions = {
        'date': 'æ—¥æœŸ (æ ¼å¼: YYYY-MM-DDï¼Œå¦‚2025-06-01)',
        'evaporation_from_bare_soil_sum': 'è£¸åœŸè’¸å‘æ€»é‡ (å•ä½: mm)',
        'total_precipitation_sum': 'æ€»é™æ°´é‡ (å•ä½: mm)',
        'temperature_2m_max': '2ç±³é«˜åº¦æœ€é«˜æ¸©åº¦ (å•ä½: Â°C)',
        'wind_speed_10m': '10ç±³é«˜åº¦é£é€Ÿ (å•ä½: m/s)'
    }

    row = 3
    for field, desc in field_descriptions.items():
        ws_guide[f'A{row}'] = field
        ws_guide[f'A{row}'].font = openpyxl.styles.Font(bold=True)
        ws_guide[f'B{row}'] = desc
        row += 1

    ws_guide['A8'] = "å¡«å†™è¦æ±‚ï¼š"
    ws_guide['A8'].font = openpyxl.styles.Font(bold=True)
    ws_guide['B8'] = f"1. å¿…é¡»æä¾›è¿ç»­{history_days}å¤©çš„å®Œæ•´æ•°æ®"
    ws_guide['B9'] = "2. æ—¥æœŸéœ€æŒ‰å‡åºæ’åˆ—"
    ws_guide['B10'] = "3. æ•°å€¼åˆ—ä¸å¯ç•™ç©ºï¼Œå¿…é¡»ä¸ºæ•°å­—"

    ws_guide.column_dimensions['A'].width = 30
    ws_guide.column_dimensions['B'].width = 60

    buffer = BytesIO()
    wb.save(buffer)
    buffer.seek(0)
    return buffer

def run_forecast_module():
    st.set_page_config(page_title="æ´ªæ°´é¢„æŠ¥", layout="centered")
    st.title("ğŸŒ§ï¸ æ´ªæ°´é¢„æŠ¥æ¨¡å—")

    st.subheader("å‚æ•°è®¾ç½®")
    history_days = st.slider("è¾“å…¥å†å²å¤©æ•°ï¼ˆHISTORY_DAYSï¼‰", min_value=7, max_value=30, value=15, step=1)
    forecast_days = st.slider("é¢„æµ‹æœªæ¥å¤©æ•°ï¼ˆFORECAST_DAYSï¼‰", min_value=1, max_value=14, value=7, step=1)

    excel_buffer = create_excel_template(history_days)

    st.download_button("ğŸ“Š ä¸‹è½½Excelæ¨¡æ¿", data=excel_buffer,
                       file_name="data_template.xlsx",
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    csv_template = "date," + ",".join(DATA_COLUMNS) + "\n" + "\n".join(["YYYY-MM-DD,,,," for _ in range(history_days)])
    st.download_button("ğŸ“„ ä¸‹è½½CSVæ¨¡æ¿", data=csv_template,
                       file_name="data_template.csv", mime="text/csv")

    st.info(f"""ğŸ’¡ è¯·ä¸Šä¼ æˆ–è¾“å…¥è¿ç»­ **{history_days} å¤©** çš„æ•°æ®ï¼Œé¢„æµ‹æœªæ¥ **{forecast_days} å¤©** çš„å¾„æµã€‚""")

    manual_input = st.checkbox("æ‰‹åŠ¨è¾“å…¥æ•°æ®")
    df = None

    if manual_input:
        text = st.text_area("è¾“å…¥æ ¼å¼ï¼šdate,evaporation_from_bare_soil_sum,total_precipitation_sum,temperature_2m_max,wind_speed_10m")
        if text:
            try:
                df = pd.read_csv(StringIO(text)) if ',' in text else pd.read_csv(StringIO(text), sep="\t")
                st.success("âœ… æ•°æ®è¯»å–æˆåŠŸ")
                st.dataframe(df.head())
            except Exception as e:
                st.error(f"âŒ æ•°æ®è¯»å–å¤±è´¥ï¼š{e}")
                return
        else:
            st.warning("è¯·è¾“å…¥æ•°æ®")
            return
    else:
        uploaded = st.file_uploader("ä¸Šä¼  CSV æˆ– Excel æ–‡ä»¶", type=["csv", "xlsx"])
        if uploaded:
            try:
                df = pd.read_csv(uploaded) if uploaded.name.endswith("csv") else pd.read_excel(uploaded)
                st.success("âœ… æ–‡ä»¶è¯»å–æˆåŠŸ")
                st.dataframe(df.head())
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{e}")
                return
        else:
            st.warning("è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶")
            return

    if not set(['date'] + DATA_COLUMNS).issubset(df.columns):
        st.error(f"âŒ æ•°æ®ç¼ºå¤±å¿…è¦åˆ—ï¼Œè¯·ç¡®ä¿åŒ…å«ï¼šdate + {DATA_COLUMNS}")
        return

    df = df.dropna()
    df['date'] = pd.to_datetime(df['date'])
    features = df[DATA_COLUMNS].values
    dates = df['date'].values

    if len(features) < history_days:
        st.error(f"âŒ æ•°æ®é•¿åº¦ä¸è¶³ {history_days} å¤©")
        return

    model = load_model()
    last_history = features[-history_days:]
    last_date = pd.to_datetime(dates[-1])
    predictions, pred_dates = [], []

    for i in range(forecast_days):
        input_tensor = torch.tensor(np.expand_dims(last_history, axis=0), dtype=torch.float32)
        with torch.no_grad():
            output = model(input_tensor)
            prediction = output.numpy()[0, -1]
            predictions.append(prediction)
        new_input = last_history[-1]
        last_history = np.vstack([last_history[1:], new_input])
        pred_dates.append(last_date + timedelta(days=i+1))

    result_df = pd.DataFrame({
        'date': pred_dates,
        'predicted_runoff': predictions
    })

    st.success("âœ… é¢„æµ‹å®Œæˆ")
    st.subheader("é¢„æµ‹ç»“æœ")
    st.line_chart(result_df.set_index('date'))
    st.dataframe(result_df)

    st.download_button("ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ", data=result_df.to_csv(index=False).encode('utf-8'), file_name="direct_forecast.csv")

# è¯·åœ¨ app.py ä¸­å¯¼å…¥æ­¤å‡½æ•°å¹¶è¿è¡Œ run_forecast_module()
