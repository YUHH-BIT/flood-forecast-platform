import streamlit as st
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import json
from datetime import timedelta
from io import StringIO, BytesIO
import openpyxl
from openpyxl.utils import get_column_letter
from openpyxl.worksheet.datavalidation import DataValidation

# å‚æ•°é…ç½®ï¼ˆåŠ¨æ€å¯è°ƒï¼‰
DATA_COLUMNS = ['evaporation_from_bare_soil_sum',
                'total_precipitation_sum',
                'temperature_2m_max',
                'wind_speed_10m']

# åŠ è½½æ¨¡å‹å‚æ•°
with open("models/best_params.json", "r") as f:
    best_params = json.load(f)

# å®šä¹‰æ¨¡å‹ï¼ˆæ”¯æŒåŠ¨æ€è¾“å…¥ç»´åº¦ï¼‰
class LSTMRunoffModel(nn.Module):
    def __init__(self, input_size, hidden_size1, hidden_size2, dropout=0.1):
        super().__init__()
        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=hidden_size1, batch_first=True)
        self.lstm2 = nn.LSTM(input_size=hidden_size1, hidden_size=hidden_size2, batch_first=True)
        self.fc = nn.Linear(hidden_size2, 1)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        out, _ = self.lstm1(x)
        out = self.dropout(out)
        out, _ = self.lstm2(out)
        out = self.fc(out)
        return out.squeeze(-1)

# åŠ è½½æ¨¡å‹
@st.cache_resource
def load_model(input_size):
    model = LSTMRunoffModel(input_size, best_params['hidden_size1'], best_params['hidden_size2'], best_params['dropout'])
    model.load_state_dict(torch.load("models/best_lstm_model.pth", map_location="cpu"))
    model.eval()
    return model

# æ ‡å‡†åŒ–
def normalize_input(data):
    return (data - data.mean()) / (data.std() + 1e-8)

# ç”ŸæˆåŠ¨æ€Excelæ¨¡æ¿
def create_excel_template(history_days):
    wb = openpyxl.Workbook()
    ws_data = wb.active
    ws_data.title = "æ•°æ®è¾“å…¥"
    ws_guide = wb.create_sheet(title="å¡«å†™æŒ‡å—")
    
    # è¡¨å¤´
    headers = ['date'] + DATA_COLUMNS
    ws_data.append(headers)
    
    # åˆ—å®½è®¾ç½®
    for col_idx, header in enumerate(headers, 1):
        col_letter = get_column_letter(col_idx)
        if header == 'date':
            ws_data.column_dimensions[col_letter].width = 15
        else:
            ws_data.column_dimensions[col_letter].width = 22
    
    # ç”ŸæˆåŠ¨æ€è¡Œæ•°çš„ç¤ºä¾‹æ•°æ®
    today = pd.Timestamp.today()
    for i in range(history_days):
        date_cell = ws_data[f'A{i+2}']
        date_cell.value = (today + timedelta(days=i)).strftime('%Y-%m-%d')
        date_cell.number_format = 'yyyy-mm-dd'
        
        # æ•°å€¼åˆ—æ•°æ®éªŒè¯
        for col_idx in range(2, len(headers)+1):
            col_letter = get_column_letter(col_idx)
            cell = ws_data[f'{col_letter}{i+2}']
            dv = DataValidation(type="decimal", operator="greaterThan", formula1="-1000")
            dv.error = 'è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å€¼ï¼'
            dv.errorTitle = 'è¾“å…¥é”™è¯¯'
            ws_data.add_data_validation(dv)
            dv.add(cell)
    
    # æç¤ºä¿¡æ¯ï¼ˆåŠ¨æ€è¡Œæ•°ï¼‰
    ws_data[f'A{history_days+3}'] = f"âš ï¸ æ³¨æ„ï¼šè¯·å¡«å†™å®Œæ•´{history_days}å¤©çš„è¿ç»­æ•°æ®ï¼Œä¸å¯ç•™ç©º"
    ws_data[f'A{history_days+3}'].font = openpyxl.styles.Font(color="FF0000", bold=True)
    
    # å¡«å†™æŒ‡å—ï¼ˆå›ºå®šå†…å®¹ï¼‰
    ws_guide['A1'] = "æ•°æ®å¡«å†™æŒ‡å—"
    ws_guide['A3'] = "å­—æ®µè¯´æ˜ï¼š"
    for idx, field in enumerate(DATA_COLUMNS, 4):
        ws_guide[f'A{idx}'] = field
        ws_guide[f'B{idx}'] = f"{field} (å•ä½: è¯·å‚è€ƒæ¨¡å‹è®­ç»ƒæ•°æ®)"
    ws_guide['A7'] = "å¡«å†™è¦æ±‚ï¼š"
    ws_guide['B7'] = "1. æ—¥æœŸéœ€æŒ‰å‡åºè¿ç»­æ’åˆ—"
    ws_guide['B8'] = "2. æ•°å€¼åˆ—ä¸å¯ç•™ç©ºï¼Œå¿…é¡»ä¸ºæ•°å­—"
    
    buffer = BytesIO()
    wb.save(buffer)
    buffer.seek(0)
    return buffer

# Streamlit ä¸»ç•Œé¢
def run_forecast_module():
    st.title("ğŸŒ§ï¸ æ´ªæ°´é¢„æŠ¥æ¨¡å—")
    
    # åŠ¨æ€å‚æ•°è°ƒèŠ‚
    st.sidebar.header("å‚æ•°è®¾ç½®")
    history_days = st.sidebar.slider(
        "å†å²æ•°æ®å¤©æ•°",
        min_value=7, max_value=30, value=15, step=1,
        help="ç”¨äºé¢„æµ‹çš„å†å²æ•°æ®å¤©æ•°ï¼ˆéœ€â‰¥7å¤©ï¼‰"
    )
    forecast_days = st.sidebar.slider(
        "é¢„æµ‹å¤©æ•°",
        min_value=1, max_value=14, value=7, step=1,
        help="æœªæ¥é¢„æµ‹çš„å¤©æ•°ï¼ˆâ‰¤14å¤©ï¼‰"
    )
    
    # æ¨¡æ¿ä¸‹è½½ï¼ˆåŠ¨æ€è¡Œæ•°ï¼‰
    st.header("ğŸ“ æ•°æ®è¾“å…¥")
    excel_buffer = create_excel_template(history_days)
    st.download_button(
        "ğŸ“Š ä¸‹è½½Excelæ¨¡æ¿",
        data=excel_buffer,
        file_name=f"data_template_{history_days}d.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
    st.download_button(
        "ğŸ“„ ä¸‹è½½CSVæ¨¡æ¿",
        data=f"date,{','.join(DATA_COLUMNS)}\n" + "\n".join([f"YYYY-MM-DD,," for _ in range(history_days)]),
        file_name=f"data_template_{history_days}d.csv",
        mime="text/csv"
    )
    
    # æ•°æ®ä¸Šä¼ 
    st.subheader("ä¸Šä¼ æ•°æ®æ–‡ä»¶")
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ CSV/Excelæ–‡ä»¶",
        type=["csv", "xlsx"],
        help=f"éœ€åŒ…å«{history_days}å¤©è¿ç»­æ•°æ®"
    )
    
    if uploaded_file:
        try:
            df = pd.read_csv(uploaded_file) if uploaded_file.name.endswith(".csv") else pd.read_excel(uploaded_file)
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
            return
        
        # æ•°æ®æ ¡éªŒ
        if not set(['date'] + DATA_COLUMNS).issubset(df.columns):
            st.error(f"ç¼ºå°‘å¿…è¦åˆ—ï¼éœ€åŒ…å«: date, {', '.join(DATA_COLUMNS)}")
            return
        if len(df) < history_days:
            st.error(f"æ•°æ®ä¸è¶³ï¼éœ€æä¾›è‡³å°‘{history_days}å¤©æ•°æ®")
            return
        
        # é¢„å¤„ç†
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date').tail(history_days)  # å–æœ€æ–°Nå¤©æ•°æ®
        features = normalize_input(df[DATA_COLUMNS].values)
        last_date = df['date'].iloc[-1]
        
        # æ¨¡å‹é¢„æµ‹
        model = load_model(input_size=len(DATA_COLUMNS))
        predictions = []
        current_data = features[np.newaxis, :, :]  # (1, history_days, input_size)
        
        for _ in range(forecast_days):
            with torch.no_grad():
                output = model(torch.from_numpy(current_data).float())
                pred = output.numpy()[-1]
                predictions.append(pred)
                
                # æ»šåŠ¨æ›´æ–°è¾“å…¥æ•°æ®ï¼ˆä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥ä½œä¸ºä¸‹ä¸€æ—¶åˆ»è¾“å…¥ï¼‰
                current_data = np.concatenate([current_data[:, 1:, :], pred.reshape(1, 1, -1)], axis=1)
        
        # ç»“æœå±•ç¤º
        st.header("ğŸ“ˆ é¢„æµ‹ç»“æœ")
        pred_dates = [last_date + timedelta(days=i+1) for i in range(forecast_days)]
        result_df = pd.DataFrame({
            'æ—¥æœŸ': pred_dates,
            'é¢„æµ‹å¾„æµé‡': predictions
        })
        st.dataframe(result_df.style.format({"é¢„æµ‹å¾„æµé‡": "{:.2f}"}))
        st.line_chart(result_df.set_index('æ—¥æœŸ'))
        
        # ä¸‹è½½ç»“æœ
        st.download_button(
            "ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ",
            data=result_df.to_csv(index=False).encode('utf-8'),
            file_name=f"forecast_{forecast_days}d.csv"
        )

if __name__ == "__main__":
    run_forecast_module()
